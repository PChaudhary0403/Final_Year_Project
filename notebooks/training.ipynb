{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PChaudhary0403/Final_Year_Project/blob/main/notebooks/training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6e74614e",
      "metadata": {
        "id": "6e74614e",
        "outputId": "25155eeb-a2c6-4643-83e6-ae91490c7bd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'bc_utils'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3183843649.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Import from our modules (you'd need to create these)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m from bc_utils import (\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mCBISDDSMDataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mBreastCancerClassifier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bc_utils'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "DATASET_PATH = \"/content/drive/MyDrive/dataset/CBIS-DDSM\"\n",
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/dataset\")\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import timm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import argparse\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import from our modules (you'd need to create these)\n",
        "from bc_utils import (\n",
        "    CBISDDSMDataset,\n",
        "    BreastCancerClassifier,\n",
        "    create_data_splits,\n",
        "    EarlyStopping,\n",
        "    save_checkpoint,\n",
        "    load_checkpoint,\n",
        "    train_epoch,\n",
        "    validate\n",
        ")\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(description='Train Breast Cancer Detection Model')\n",
        "    parser.add_argument('--epochs', type=int, default=20, help='Number of training epochs')\n",
        "    parser.add_argument('--batch_size', type=int, default=8, help='Batch size for training')\n",
        "    parser.add_argument('--lr', type=float, default=1e-3, help='Learning rate')\n",
        "    parser.add_argument('--data_path', type=str, default='/content/dataset/CBIS-DDSM',\n",
        "                        help='Path to CBIS-DDSM dataset')\n",
        "    parser.add_argument('--checkpoint_path', type=str, default='/content/checkpoints/model.pth',\n",
        "                        help='Path to save checkpoints')\n",
        "    parser.add_argument('--model_path', type=str, default='/content/models/best_model.pth',\n",
        "                        help='Path to save best model')\n",
        "    parser.add_argument('--resume', action='store_true', help='Resume training from checkpoint')\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # Setup device\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Create data splits\n",
        "    print(\"Loading dataset...\")\n",
        "    train_data, val_data, test_data = create_data_splits()\n",
        "\n",
        "    # Data transforms (simplified)\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((512, 512)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = CBISDDSMDataset(*train_data, transform=transform, is_training=True)\n",
        "    val_dataset = CBISDDSMDataset(*val_data, transform=transform, is_training=False)\n",
        "    test_dataset = CBISDDSMDataset(*test_data, transform=transform, is_training=False)\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True,\n",
        "                            num_workers=2, pin_memory=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False,\n",
        "                          num_workers=2, pin_memory=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False,\n",
        "                           num_workers=2, pin_memory=True)\n",
        "\n",
        "    # Create model\n",
        "    model = BreastCancerClassifier(num_classes=2).to(device)\n",
        "\n",
        "    # Loss function and optimizer\n",
        "    class_counts = np.bincount(train_data[1])\n",
        "    class_weights = 1.0 / class_counts\n",
        "    class_weights = class_weights / class_weights.sum() * len(class_weights)\n",
        "    class_weights = torch.FloatTensor(class_weights).to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "    backbone_params = list(model.backbone.parameters())\n",
        "    classifier_params = list(model.classifier.parameters())\n",
        "\n",
        "    optimizer = optim.AdamW([\n",
        "        {'params': backbone_params, 'lr': args.lr * 0.1},\n",
        "        {'params': classifier_params, 'lr': args.lr}\n",
        "    ], weight_decay=1e-4)\n",
        "\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='max', factor=0.5, patience=3, verbose=True\n",
        "    )\n",
        "\n",
        "    # Load checkpoint if resuming\n",
        "    start_epoch, best_loss, best_accuracy = 0, float('inf'), 0.0\n",
        "    if args.resume:\n",
        "        start_epoch, best_loss, best_accuracy = load_checkpoint(\n",
        "            model, optimizer, scheduler, args.checkpoint_path\n",
        "        )\n",
        "\n",
        "    # Training loop\n",
        "    early_stopping = EarlyStopping(patience=5)\n",
        "    train_losses, val_losses = [], []\n",
        "    train_accuracies, val_accuracies = [], []\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "    for epoch in range(start_epoch, args.epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{args.epochs}\");\n",
        "\n",
        "        # Train\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_acc)\n",
        "\n",
        "        # Validate\n",
        "        val_loss, val_acc, _, _, _ = validate(model, val_loader, criterion, device)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracies.append(val_acc)\n",
        "\n",
        "        print(\".4f\")\n",
        "        # Update learning rate\n",
        "        scheduler.step(val_acc)\n",
        "\n",
        "        # Save checkpoint\n",
        "        save_checkpoint(model, optimizer, scheduler, epoch+1, val_loss, val_acc, args.checkpoint_path)\n",
        "\n",
        "        # Save best model\n",
        "        if val_acc > best_accuracy:\n",
        "            best_accuracy = val_acc\n",
        "            torch.save(model.state_dict(), args.model_path)\n",
        "            print(\".2f\")\n",
        "        # Early stopping\n",
        "        early_stopping(val_loss)\n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping triggered!\")\n",
        "            break\n",
        "\n",
        "    # Final evaluation\n",
        "    print(\"\\nEvaluating best model...\")\n",
        "    model.load_state_dict(torch.load(args.model_path, map_location=device))\n",
        "    test_loss, test_acc, test_preds, test_labels, test_probs = validate(model, test_loader, criterion, device)\n",
        "\n",
        "    print(\".2f\")\n",
        "    # Calculate metrics\n",
        "    from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "    precision = precision_score(test_labels, test_preds, average='weighted')\n",
        "    recall = recall_score(test_labels, test_preds, average='weighted')\n",
        "    f1 = f1_score(test_labels, test_preds, average='weighted')\n",
        "    auc = roc_auc_score(test_labels, np.array(test_probs)[:, 1])\n",
        "\n",
        "    print(\".4f\")\n",
        "    print(\"Training completed successfully!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(\"Exists?\",\n",
        "      os.path.exists(\"/content/drive/MyDrive/BreastCancerProject/Breast_Cancer_Detection_Colab.py\"))\n",
        "\n",
        "print(\"Files in folder:\")\n",
        "print(os.listdir(\"/content/drive/MyDrive/BreastCancerProject\"))\n"
      ],
      "metadata": {
        "id": "b1l3UZTDlpE5",
        "outputId": "4cac0a37-2dad-4c05-d2fb-6f6b0761874d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "b1l3UZTDlpE5",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exists? True\n",
            "Files in folder:\n",
            "['Breast_Cancer_Detection_Colab.ipynb', 'Imagefolder', 'CBIS-DDSM', 'Breast_Cancer_Detection_Colab.py', '__pycache__']\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}